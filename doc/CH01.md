카프카는 링크드인에서 사용자 활동 추적이 처음 의도였다.

모든 기업은 데이터로 움직인다. 우리는 정보를 얻고, 분석하고, 가공하고, 그 이상의 것을 결과물로 산출한다. 그리고 모든 애플리케이션은 로그, 지표, 사용자 행동, 외부 메시지 등의 데이터를 매 순간 생성한다.

이러한 작업을 더 빠르게 해낼수록 조직은 더 유연해지고 더 민첩해질 수 있다. 데이터가 중심이 되는 기업에서 파이프라인이 중요한 핵심적인 요소가 되는 이유는 데이터를 이동시키는 작업에 더 적은 노력을 들이고, 핵심 비즈니스에 더욱 집중하는 것에 있기 때문이다.

## 발행 / 구독 메시지 전달

발행/구독 메시지 전달 패턴의 특징은 전송자가 데이터를 보낼 때 직접 수신자로 보내지 않는다는 것이다. 대신, 전송자는 어떤 형태로든 메시지를 분류해서 보내고, 수신자는 이렇게 분류된 메시지를 구독한다. 이러한 시스템에는 메시지를 전달받고 중계해주는 역할이 있고, 이를 브로커(broker)라고 한다.

## 초기의 발행 / 구독 시스템

발행/구독 패턴을 따르는 많은 사례들은 비슷한 형태로 시작한다. 즉, 가운데 메시지 큐나 프로세스간 통신 채널을 놓는 것이다. 하지만 이러한 구조는 구독자와 발행자가 늘어나면 아키텍쳐의 복잡도가 올라가게 되고, 결국 이러한 복잡도는 기술 부채로 이어진다. 이를 해결하기 위해서는 발행/구독을 수행하는 별도의 서버를 제공하면 된다.

하지만 채널이 늘어난다면 이 해결책 또한 문제가 발생한다. 중복이 늘어날 수 있고 중복이 늘어난다는 것은 하나의 버그가 중복이 되는 모든 곳에 숨어들었을 수 있기 때문이다.

비즈니스가 확잠됨에 따라 함께 확장되는, 일반화된 유형의 데이터를 발행하고 구독할 수 있는 중앙 집중화된 시스템이 필요하게 된다.

## 카프카 시작하기
아프치 카프카는 위에서 설명한 것과 같은 문제를 해결하기 위해 고안된 메시지 발행/구독 시스템이다. 다른 이름으로는 '분산 커밋 로그' 또는 '분산 스프리밍 플랫폼'이라고 불린다.

파일시스템이나 데이터베이스 커밋 로그는 모든 트랜잭션 기록을 지속성이 있게 보존함으로써 시스템의 상태를 일관성 있게 복구할 수 있도록 고안되었다. MySQL의 경우에도 로그 데이터를 기준으로 백업을 수행하고, 이를 통해 데이터베이스의 일관성을 유지할 수 있다.

이와 유사하게, 카프카는 저장된 데이터의 순서를 유지한 채로 지속성있게 보관하며 결정적으로 읽을 수 있다. 또한, 카프카 시스템 안에서 데이터를 분산시켜 저장할 수 있기 때문에, 확장시 성능을 향상시키고 실패가 발생해도 데이터 사용에는 문제가 없다.

## 메시지와 배치
카프카에서 데이터의 기본 단위는 메시지다. 메시지는 단순한 바이트 배열일 뿐이기 때문에 여기에 포함된 데이터에는 특정한 형식이나 의미가 없다. 메시지는 키라는 메타 데이터를 포함할 수 있다. 키는 메시지를 저장할 파티션을 결정하기 위해 사용된다. 파티션을 구분하는 가장 간단한 방법은 키를 통해 해시값을 생성하고 이 값을 모듈로 연산한 결과로 파티션을 구분 및 저장하는 것이다.

카프카는 효율성을 위해서 메시지를 배치(batch)단위로 저장한다. 배치는 같은 토픽의 파티션에 쓰여지는 메시지드의 집합일 뿐이다. 지연과 처리량 사이에 트레이드 오프를 발생시킨다.


## 스키마
카프카 입장에서는 메시지를 단순한 바이트 배열일 뿐이지만, 내용을 이해하기 쉽도록 일정한 구조를 부여하는 것이 권장된다. 가장 간단한 방법으로는 쓰기 쉽고 가독성이 좋은 JSON, XML이 있다. 하지만 이 방식들은 타입 처리 기능이나 스키마 버전 간의 호환성 유지 기능이 떨어진다. 많은 카프카 개발자들은 아파치 에으브로(Avro)를 선호한다. 이는 직렬화 프레임워크로 원래는 하둡 프로젝트를 위해 개발된 것이다.

카프카에서는 일관적인 데이터 형식이 중요하다. 메시지 쓰기와 읽기 작업을 분리할 수 있도록 해주기 때문이다. 즉, 적절한 직렬화는 발행과 구독의 원할한 메시지 상호작용을 가능하게 한다. -> 추가적인 이해가 필요하다.

## 토픽과 파티션

카프카에 저장되는 메시지는 토픽(topic)단위로 분류된다. 토픽과 가장 비슷한 개념은 데이터베이스의 테이블이나 파일시스템의 폴더가 있을 것이다. 토픽은 다시 여러 개의 파티션(partition)으로 나뉘어진다. 파티션은 하나의 로그에 해당하며, 메시지를 쓰여질 때는 추가만 가능한 형태이고 읽은 때는 맨앞에서 부터 순서로 읽힌다. 토픽 내부에는 여러 개의 파티션이 있는 만큼 토픽 안의 메시지 전체에 대한 순서를 보장하지는 않는다. 하지만 파티션 내부에서는 각 메시지간의 순서가 보장된다.


## 프로듀서와 컨슈머

카프카 클라이언트에는 프로듀서와 컨슈머가 있다. 좀더 고급 API로는 데이터 통합에 사용되는 카프카 커넥트 API와 스트림 처리에 사용되는 카프카 스트림즈가 있다.

프로듀서는 새로운 메시지를 생성한다. 다른 발생/구독 시스템에서는 발행자 혹은 작성자라고 부른다. 프로듀서는 메시지를 쓸 때 토픽에 속한 파티션들 사이에 고르게 나눠서 쓰도록 되어 있다.  각 피티션은 메시지 키와 키값의 해시를 특정 파티션으로 대응시켜주는 파티셔너를 사용해서 구현된다. 그렇기 때문에 같은 키를 가진 메시지는 같은 파티션에 저장된다.

컨슈머는 새로운 메시지를 읽고, 다른 발행/구독 시스템에서는 구독자 혹은 독자라고 부른다. 컨슈머는 1개 이상의 토픽을 구독해서 저장된 메시지들을 각 파티션에 쓰여진 순서대로 읽어 온다. 컨슈머는 메시지의 오프셋을 기록함으로써 어느 메시지까지 읽었는지 유지할 수 있다. 여기서 오프셋은 카프카에서 메시지를 저장할 때 각 메시지에 부여해주는 메타데이터이다.

컨슈머는 컨슈머 그룹의 일원으로서 작동한다. 컨슈머 그룹은 토픽에 저장된 데이터를 읽어오기 위해 협업하는 하나 이상의 컨슈머로 이루어진다. 컨슈머 그룹은 각 파티션이 하나의 컨슈머에 의해서만 읽히도록 한다. 즉, 컨슈머는 파티션에 대한 소유권을 갖는다.

## 브로커와 클러스터

하나의 카프카 서버를 브로커라고 부른다. 하나의 브로커는 초당 수천 개의 파티션과 수백만 개의 메시지를 쉽게 처리할 수 있다.

카프카의 브로커는 클러스터의 일부로서 작동하도록 설계되었다. 하나의 클러스터 안에 여러 개의 브로커가 포함될 수 있으며, 그중 하나의 브로커가 클러스터 컨트롤러의 역할을 하게 된다. 그리고 컨트롤러의 역할을 하는 브로커를 파티션 리더라고 부른다.

아파치 카프카의 핵심 기능 중에 일정 기간 동안 메시지를 지속성있게 보관하는 보존기능이 있다.  -> 여러가지 설정이 있음. 추후에 나옴

카프카 클러스터의 복제 메커니즘은 다중 클러스터 사이에서가 아닌 하나의 클러스터 안에서만 작동하도록 설계되어 있다.
